{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled84.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTZ9tnN6ZifV"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import csv\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_10k2AGpVE9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "11cacc87-72c2-4229-e774-db889a0e652c"
      },
      "source": [
        "df = pd.read_csv('/content/Train.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text_ID</th>\n",
              "      <th>Product_Description</th>\n",
              "      <th>Product_Type</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3057</td>\n",
              "      <td>The Web DesignerÛªs Guide to iOS (and Android...</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6254</td>\n",
              "      <td>RT @mention Line for iPad 2 is longer today th...</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8212</td>\n",
              "      <td>Crazy that Apple is opening a temporary store ...</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4422</td>\n",
              "      <td>The lesson from Google One Pass: In this digit...</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5526</td>\n",
              "      <td>RT @mention At the panel: &amp;quot;Your mom has a...</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Text_ID  ... Sentiment\n",
              "0     3057  ...         2\n",
              "1     6254  ...         2\n",
              "2     8212  ...         2\n",
              "3     4422  ...         2\n",
              "4     5526  ...         2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc7p7vxRpkAX"
      },
      "source": [
        "sentences = np.array(df['Product_Description'].values)\n",
        "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGqLljOmikWm"
      },
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'@[a-zA-Z0-9_]+', '', text)   \n",
        "    text = re.sub(r'https?://[A-Za-z0-9./]+', '', text)   \n",
        "    text = re.sub(r'www.[^ ]+', '', text)  \n",
        "    text = re.sub(r'[a-zA-Z0-9]*www[a-zA-Z0-9]*com[a-zA-Z0-9]*', '', text)  \n",
        "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
        "    for word in stopwords:\n",
        "      token= ' '+word+' '\n",
        "      text = text.replace(word,' ')\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tnr-l5H-iw2a"
      },
      "source": [
        "cleared_sentences = []\n",
        "for sentence in sentences:\n",
        "  sentence= clean_text(sentence)\n",
        "  cleared_sentences.append(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwyTvHnol_kF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b71c199-b63d-47a6-e4c5-245a1c08850e"
      },
      "source": [
        "df.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6364, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TfBzUwCmXY9"
      },
      "source": [
        "train_size = 6000\n",
        "labels = pd.get_dummies(df['Sentiment']).values\n",
        "train_sentences = cleared_sentences[:train_size]\n",
        "test_sentences = cleared_sentences[train_size:]\n",
        "test_labels = labels[train_size:]\n",
        "train_labels = labels[:train_size]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8w9CnrAtJPz"
      },
      "source": [
        "tokenizer = Tokenizer(num_words= 3000,split= ' ')\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "seq = tokenizer.texts_to_sequences(train_sentences)\n",
        "pad_train_seq = pad_sequences(seq)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POd06eU0tMRO"
      },
      "source": [
        "tokenizer = Tokenizer(num_words= 3000,split= ' ')\n",
        "tokenizer.fit_on_texts(test_sentences)\n",
        "seq = tokenizer.texts_to_sequences(test_sentences)\n",
        "pad_test_seq = pad_sequences(seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wfsbAVCt2l-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce1749c1-e68d-4c82-8fe3-dc9d31e95e07"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Embedding(3000,128,input_length= pad_train_seq.shape[1]),\n",
        "                                    tf.keras.layers.SpatialDropout1D(0.9),\n",
        "                                    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128,return_sequences=True)),\n",
        "                                    tf.keras.layers.Dropout(0.9),\n",
        "                                    tf.keras.layers.LSTM(120,dropout=0.2,recurrent_dropout=0.2),\n",
        "                                    tf.keras.layers.Dense(4,activation='softmax')\n",
        "\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1z6N69Iur5C"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer= 'adam',metrics =['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxcGKoQ0u2D4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e8ec90-fa15-40da-d8e1-ea3889c4ad2c"
      },
      "source": [
        "model.fit(pad_train_seq,train_labels,validation_data= (pad_test_seq,test_labels),epochs=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.9337 - accuracy: 0.5908WARNING:tensorflow:Model was constructed with shape (None, 42) for input Tensor(\"embedding_5_input:0\", shape=(None, 42), dtype=float32), but it was called on an input with incompatible shape (None, 37).\n",
            "188/188 [==============================] - 51s 271ms/step - loss: 0.9337 - accuracy: 0.5908 - val_loss: 1.0794 - val_accuracy: 0.5137\n",
            "Epoch 2/32\n",
            "188/188 [==============================] - 49s 263ms/step - loss: 0.9007 - accuracy: 0.5980 - val_loss: 1.0528 - val_accuracy: 0.5137\n",
            "Epoch 3/32\n",
            "188/188 [==============================] - 50s 266ms/step - loss: 0.8826 - accuracy: 0.6068 - val_loss: 1.0601 - val_accuracy: 0.5165\n",
            "Epoch 4/32\n",
            "188/188 [==============================] - 50s 267ms/step - loss: 0.8586 - accuracy: 0.6277 - val_loss: 1.0686 - val_accuracy: 0.5000\n",
            "Epoch 5/32\n",
            "188/188 [==============================] - 50s 267ms/step - loss: 0.8377 - accuracy: 0.6418 - val_loss: 1.0811 - val_accuracy: 0.4918\n",
            "Epoch 6/32\n",
            "188/188 [==============================] - 50s 267ms/step - loss: 0.8218 - accuracy: 0.6577 - val_loss: 1.1158 - val_accuracy: 0.4808\n",
            "Epoch 7/32\n",
            "188/188 [==============================] - 50s 268ms/step - loss: 0.8100 - accuracy: 0.6613 - val_loss: 1.0907 - val_accuracy: 0.4725\n",
            "Epoch 8/32\n",
            "188/188 [==============================] - 50s 268ms/step - loss: 0.7864 - accuracy: 0.6795 - val_loss: 1.1946 - val_accuracy: 0.5000\n",
            "Epoch 9/32\n",
            "188/188 [==============================] - 50s 266ms/step - loss: 0.7784 - accuracy: 0.6842 - val_loss: 1.1737 - val_accuracy: 0.4863\n",
            "Epoch 10/32\n",
            "188/188 [==============================] - 50s 267ms/step - loss: 0.7632 - accuracy: 0.6930 - val_loss: 1.1477 - val_accuracy: 0.4725\n",
            "Epoch 11/32\n",
            "188/188 [==============================] - 50s 266ms/step - loss: 0.7505 - accuracy: 0.6967 - val_loss: 1.1627 - val_accuracy: 0.4835\n",
            "Epoch 12/32\n",
            "188/188 [==============================] - 51s 269ms/step - loss: 0.7291 - accuracy: 0.7085 - val_loss: 1.1515 - val_accuracy: 0.4945\n",
            "Epoch 13/32\n",
            "188/188 [==============================] - 50s 267ms/step - loss: 0.7318 - accuracy: 0.7065 - val_loss: 1.1841 - val_accuracy: 0.4533\n",
            "Epoch 14/32\n",
            "188/188 [==============================] - 50s 268ms/step - loss: 0.7228 - accuracy: 0.7142 - val_loss: 1.1828 - val_accuracy: 0.4780\n",
            "Epoch 15/32\n",
            "188/188 [==============================] - 50s 267ms/step - loss: 0.7061 - accuracy: 0.7262 - val_loss: 1.2512 - val_accuracy: 0.4808\n",
            "Epoch 16/32\n",
            "188/188 [==============================] - 51s 269ms/step - loss: 0.6986 - accuracy: 0.7205 - val_loss: 1.2617 - val_accuracy: 0.4670\n",
            "Epoch 17/32\n",
            "188/188 [==============================] - 50s 268ms/step - loss: 0.6815 - accuracy: 0.7317 - val_loss: 1.2404 - val_accuracy: 0.4560\n",
            "Epoch 18/32\n",
            "188/188 [==============================] - 51s 269ms/step - loss: 0.6749 - accuracy: 0.7335 - val_loss: 1.2353 - val_accuracy: 0.4533\n",
            "Epoch 19/32\n",
            "188/188 [==============================] - 50s 266ms/step - loss: 0.6577 - accuracy: 0.7450 - val_loss: 1.3086 - val_accuracy: 0.4643\n",
            "Epoch 20/32\n",
            "188/188 [==============================] - 50s 264ms/step - loss: 0.6603 - accuracy: 0.7390 - val_loss: 1.3561 - val_accuracy: 0.4808\n",
            "Epoch 21/32\n",
            "188/188 [==============================] - 49s 262ms/step - loss: 0.6562 - accuracy: 0.7467 - val_loss: 1.2830 - val_accuracy: 0.4890\n",
            "Epoch 22/32\n",
            "188/188 [==============================] - 50s 265ms/step - loss: 0.6450 - accuracy: 0.7452 - val_loss: 1.3012 - val_accuracy: 0.4560\n",
            "Epoch 23/32\n",
            "188/188 [==============================] - 50s 265ms/step - loss: 0.6469 - accuracy: 0.7447 - val_loss: 1.3423 - val_accuracy: 0.4451\n",
            "Epoch 24/32\n",
            "188/188 [==============================] - 50s 266ms/step - loss: 0.6351 - accuracy: 0.7502 - val_loss: 1.2960 - val_accuracy: 0.4643\n",
            "Epoch 25/32\n",
            "188/188 [==============================] - 50s 265ms/step - loss: 0.6308 - accuracy: 0.7567 - val_loss: 1.3948 - val_accuracy: 0.4560\n",
            "Epoch 26/32\n",
            "188/188 [==============================] - 50s 264ms/step - loss: 0.6197 - accuracy: 0.7567 - val_loss: 1.2936 - val_accuracy: 0.4478\n",
            "Epoch 27/32\n",
            "188/188 [==============================] - 50s 267ms/step - loss: 0.6070 - accuracy: 0.7633 - val_loss: 1.3747 - val_accuracy: 0.4533\n",
            "Epoch 28/32\n",
            "188/188 [==============================] - 50s 266ms/step - loss: 0.6026 - accuracy: 0.7673 - val_loss: 1.4492 - val_accuracy: 0.4753\n",
            "Epoch 29/32\n",
            "188/188 [==============================] - 50s 264ms/step - loss: 0.5999 - accuracy: 0.7703 - val_loss: 1.3401 - val_accuracy: 0.4698\n",
            "Epoch 30/32\n",
            "188/188 [==============================] - 50s 264ms/step - loss: 0.5981 - accuracy: 0.7703 - val_loss: 1.3638 - val_accuracy: 0.4560\n",
            "Epoch 31/32\n",
            "188/188 [==============================] - 50s 266ms/step - loss: 0.5874 - accuracy: 0.7742 - val_loss: 1.3449 - val_accuracy: 0.4643\n",
            "Epoch 32/32\n",
            "188/188 [==============================] - 50s 266ms/step - loss: 0.5841 - accuracy: 0.7695 - val_loss: 1.3780 - val_accuracy: 0.4753\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0832a76c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGV1xKE5vA47"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}